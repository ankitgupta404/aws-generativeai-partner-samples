{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Evaluate Retrieval Augmented Generation with Elastic, Anthropic Claude 3.7, Amazon Bedrock, Langchain and RAGAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we will show you how to use Langchain, Anthropic Claude 3.7, Elastic and RAGAS to build and evaluate response of a Retrieval Augmented Generation (RAG) solution\n",
    "\n",
    "\n",
    "#### Use case\n",
    "\n",
    "Evaluation of RAG (Retrieval-Augmented Generation) Application for Private Documentation Question Answering \n",
    "\n",
    "\n",
    "#### Persona\n",
    "As an analyst at Anycompany, Bob wants to evaluate the response of a Retrieval-Augmented Generation (RAG) application for answering questions based on the company's private documentation. The RAG application combines information retrieval and language generation techniques to provide accurate and relevant answers to users' questions. \n",
    "\n",
    "#### Implementation\n",
    "To fulfill this use case, in this notebook we will show how to evaluate a RAG Application to answer questions from business data. We will use the Anthropic Claude 3.7 Sonnet Foundation model, Elastic, Langchain and RAGAS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python 3.10\n",
    "\n",
    "⚠  For this lab we need to run the notebook based on a Python 3.10 runtime. ⚠\n",
    "\n",
    "\n",
    "## Installation\n",
    "\n",
    "To run this notebook you would need to install dependencies - boto3, botocore, elasticsearch and langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.11/site-packages (25.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.36.12 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.3 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires pytz<=2024.2,>=2023.3, but you have pytz 2025.1 which is incompatible.\n",
      "mlflow 2.20.0 requires pyarrow<19,>=4.0.0, but you have pyarrow 19.0.0 which is incompatible.\n",
      "s3fs 2024.10.0 requires fsspec==2024.10.0.*, but you have fsspec 2024.9.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires attrs<24,>=23.1.0, but you have attrs 25.1.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.36.12 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires pytz<=2024.2,>=2023.3, but you have pytz 2025.1 which is incompatible.\n",
      "mlflow 2.20.0 requires pyarrow<19,>=4.0.0, but you have pyarrow 19.0.0 which is incompatible.\n",
      "s3fs 2024.10.0 requires fsspec==2024.10.0.*, but you have fsspec 2024.9.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires attrs<24,>=23.1.0, but you have attrs 25.1.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "dash 2.18.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-table==5.0.0, which is not installed.\n",
      "jupyter-ai 2.29.0 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.36.12 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "dash 2.18.1 requires Flask<3.1,>=1.0.4, but you have flask 3.1.0 which is incompatible.\n",
      "dash 2.18.1 requires Werkzeug<3.1, but you have werkzeug 3.1.3 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires pytz<=2024.2,>=2023.3, but you have pytz 2025.1 which is incompatible.\n",
      "mlflow 2.20.0 requires pyarrow<19,>=4.0.0, but you have pyarrow 19.0.0 which is incompatible.\n",
      "s3fs 2024.10.0 requires fsspec==2024.10.0.*, but you have fsspec 2024.9.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires attrs<24,>=23.1.0, but you have attrs 25.1.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "dash 2.18.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-table==5.0.0, which is not installed.\n",
      "jupyter-ai 2.29.0 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.36.12 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.3 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "dash 2.18.1 requires Flask<3.1,>=1.0.4, but you have flask 3.1.0 which is incompatible.\n",
      "dash 2.18.1 requires Werkzeug<3.1, but you have werkzeug 3.1.3 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires pytz<=2024.2,>=2023.3, but you have pytz 2025.1 which is incompatible.\n",
      "mlflow 2.20.0 requires pyarrow<19,>=4.0.0, but you have pyarrow 19.0.0 which is incompatible.\n",
      "s3fs 2024.10.0 requires fsspec==2024.10.0.*, but you have fsspec 2024.9.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires attrs<24,>=23.1.0, but you have attrs 25.1.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "dash 2.18.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-table==5.0.0, which is not installed.\n",
      "jupyter-ai 2.29.0 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.36.12 which is incompatible.\n",
      "amazon-sagemaker-jupyter-ai-q-developer 1.0.16 requires numpy<=2.0.1, but you have numpy 2.2.2 which is incompatible.\n",
      "autogluon-common 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.2 which is incompatible.\n",
      "autogluon-core 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.2 which is incompatible.\n",
      "autogluon-features 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.2 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.2 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "autogluon-tabular 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.2 which is incompatible.\n",
      "autogluon-timeseries 1.2 requires numpy<2.1.4,>=1.25.0, but you have numpy 2.2.2 which is incompatible.\n",
      "catboost 1.2.7 requires numpy<2.0,>=1.16.0, but you have numpy 2.2.2 which is incompatible.\n",
      "dash 2.18.1 requires Flask<3.1,>=1.0.4, but you have flask 3.1.0 which is incompatible.\n",
      "dash 2.18.1 requires Werkzeug<3.1, but you have werkzeug 3.1.3 which is incompatible.\n",
      "gluonts 0.16.0 requires numpy<2.2,>=1.16, but you have numpy 2.2.2 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires pytz<=2024.2,>=2023.3, but you have pytz 2025.1 which is incompatible.\n",
      "mlflow 2.20.0 requires pyarrow<19,>=4.0.0, but you have pyarrow 19.0.0 which is incompatible.\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.2 which is incompatible.\n",
      "s3fs 2024.10.0 requires fsspec==2024.10.0.*, but you have fsspec 2024.9.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires attrs<24,>=23.1.0, but you have attrs 25.1.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires numpy<2.0,>=1.9.0, but you have numpy 2.2.2 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\n",
      "langchain 0.3.17 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
      "langchain-aws 0.2.12 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
      "langchain-community 0.3.16 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.36.12 which is incompatible.\n",
      "mlflow 2.20.0 requires pyarrow<19,>=4.0.0, but you have pyarrow 19.0.0 which is incompatible.\n",
      "s3fs 2024.10.0 requires fsspec==2024.10.0.*, but you have fsspec 2024.9.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires attrs<24,>=23.1.0, but you have attrs 25.1.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires numpy<2.0,>=1.9.0, but you have numpy 2.2.2 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\n",
      "langchain 0.3.17 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\n",
      "langchain-community 0.3.16 requires numpy<2,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 1.2 requires nvidia-ml-py3==7.352.0, which is not installed.\n",
      "dash 2.18.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.18.1 requires dash-table==5.0.0, which is not installed.\n",
      "jupyter-ai 2.29.0 requires faiss-cpu!=1.8.0.post0,<2.0.0,>=1.8.0, which is not installed.\n",
      "aiobotocore 2.19.0 requires botocore<1.36.4,>=1.36.0, but you have botocore 1.36.12 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.3 requires sqlparse==0.5.0, but you have sqlparse 0.5.3 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires jsonschema<4.22,>=4.18, but you have jsonschema 4.23.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires nltk<3.9,>=3.4.5, but you have nltk 3.9.1 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires omegaconf<2.3.0,>=2.1.1, but you have omegaconf 2.3.0 which is incompatible.\n",
      "blis 1.0.1 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "dash 2.18.1 requires Flask<3.1,>=1.0.4, but you have flask 3.1.0 which is incompatible.\n",
      "dash 2.18.1 requires Werkzeug<3.1, but you have werkzeug 3.1.3 which is incompatible.\n",
      "jupyter-scheduler 2.10.0 requires pytz<=2024.2,>=2023.3, but you have pytz 2025.1 which is incompatible.\n",
      "mlflow 2.20.0 requires pyarrow<19,>=4.0.0, but you have pyarrow 19.0.0 which is incompatible.\n",
      "pathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\n",
      "s3fs 2024.10.0 requires fsspec==2024.10.0.*, but you have fsspec 2024.9.0 which is incompatible.\n",
      "sagemaker 2.228.0 requires attrs<24,>=23.1.0, but you have attrs 25.1.0 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install boto3 --force-reinstall --quiet\n",
    "%pip install botocore --force-reinstall --quiet\n",
    "%pip install langchain --force-reinstall --quiet\n",
    "%pip install langchain-aws --force-reinstall --quiet\n",
    "%pip install langchain-elasticsearch --force-reinstall --quiet\n",
    "%pip install elasticsearch==8.18.0 --force-reinstall --quiet\n",
    "%pip install pypdf --force-reinstall --quiet\n",
    "%pip install ragas==0.2.6 --force-reinstall --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Restart\n",
    "\n",
    "Restart the kernel with the updated packages that are installed through the dependencies above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Setup \n",
    "\n",
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [],
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import botocore\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws import AmazonKnowledgeBasesRetriever\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from botocore.client import Config\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.chains import RetrievalQA\n",
    "from getpass import getpass\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Initialization\n",
    "\n",
    "Initiate Bedrock Runtime and BedrockChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n",
    "bedrock_client = boto3.client('bedrock-runtime')\n",
    "\n",
    "modelId = 'us.anthropic.claude-3-7-sonnet-20250219-v1:0' # change this to use a different version from the model provider\n",
    "embeddingmodelId = 'amazon.titan-embed-text-v2:0' # change this to use a different embedding model\n",
    "\n",
    "llm = ChatBedrockConverse(model_id=modelId, client=bedrock_client)\n",
    "embeddings = BedrockEmbeddings(model_id=embeddingmodelId,client=bedrock_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files from directory\n",
    "\n",
    "Load all PDF files which are present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/sagemaker-user/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TMP_DIR = os.path.join(os.path.dirname(os.path.realpath('__file__')), 'media/2018-SaoE-Enhancing_the_Simulation_of_Complex_Mechanical_Systems_with_Machine_Learning.pdf')\n",
    "loader = PyPDFLoader(TMP_DIR)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Documents\n",
    "\n",
    "Chunk documents into passages in order to improve the retrieval specificity and to ensure that we can provide multiple passages within the context window of the final question answering prompt.\n",
    "\n",
    "Here we are chunking documents into 1000 token passages with an overlap of 0 tokens.\n",
    "\n",
    "Here we are using Recursive Character Text splitter but Langchain offers more advanced splitters to reduce the chance of context being lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=['\\n\\n', '\\n', '.', ','],\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=0\n",
    "        )\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Elasticsearch\n",
    "\n",
    "We'll use the Cloud ID to identify our deployment, because we are using Elastic Cloud deployment. To find the Cloud ID for your deployment, go to [Cloud ID](https://cloud.elastic.co/deployments) and select your deployment.\n",
    "\n",
    "We will use ElasticsearchStore to connect to our elastic cloud deployment. This would help create and index data easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic deployment Cloud ID:  ········\n",
      "Elastic deployment API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "cloud_id = getpass(\"Elastic deployment Cloud ID: \")\n",
    "cloud_api_key = getpass(\"Elastic deployment API Key: \")\n",
    "index_name= \"new-index-1\"\n",
    "\n",
    "vector_store = ElasticsearchStore(\n",
    "        es_cloud_id=cloud_id,  \n",
    "        index_name= index_name, \n",
    "        embedding=embeddings,\n",
    "        es_api_key=cloud_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index data into Elasticsearch and initialize retriever\n",
    "\n",
    "Next, we will index data to elasticsearch using ElasticsearchStore.from_documents. We will use Cloud ID, Password and Index name values set in the Create cloud deployment step. We will set embedding to BedrockEmbeddings to embed the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectordb = vector_store.from_documents(\n",
    "        texts, \n",
    "        embeddings,\n",
    "        index_name=index_name,\n",
    "        es_cloud_id=cloud_id,\n",
    "        es_api_key=cloud_api_key\n",
    "        )\n",
    "\n",
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Invocation and Response Generation using RetrievalQA chain\n",
    "\n",
    "Now that we have the passages stored in Elasticsearch and LLM is initialized, we can now ask a question to get the relevant passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine learning is a technique that allows predictions or decisions to be made from data. It involves steps like:\n",
      "\n",
      "1. Framing the problem - Determining what question you are trying to answer and what data is needed.\n",
      "\n",
      "2. Training an algorithm - Providing data to a machine learning algorithm like linear regression, decision trees, neural networks etc. to create a model that maps the input data to the desired output.\n",
      "\n",
      "3. Evaluating the model - Checking the model's performance on test data that was not used for training to ensure it generalizes well.\n",
      "\n",
      "The context provided mentions that machine learning has flourished in recent years due to increased computing power and user-friendly toolkits. It allows finding patterns and making predictions from data in fields ranging from spam filtering to self-driving cars. The key aspects are having relevant data and selecting the appropriate algorithm for the problem at hand.\n",
      "</response>\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Machine learning?\"\n",
    "\n",
    "\n",
    "machinelearning_advisor_template = \"\"\"\n",
    "    Human: You will be acting as a Machine Learning advisor on complex Mechanical systems named Poly created by the company Polymath. \n",
    "    Your goal is to give advice related to Application of Machine Learning on Mechanical Systems to users. You will be replying to users \n",
    "    who are asking questions on Application of Machine Learning in Mechanical Systems \n",
    "    site and who will be confused if you don't respond in the character of Poly.\n",
    "    \n",
    "    You should maintain a friendly customer service tone.\n",
    "\n",
    "    Here is the document you should reference when answering the user: <context>{context}</context>\n",
    "\n",
    "    Here are some important rules for the interaction:\n",
    "    - Always stay in character, as Poly, a Machine Learning advisor on complex Mechanical systems\n",
    "    - If you are unsure how to respond, say “Sorry, I didn’t understand that. Could you repeat the question?”\n",
    "    - If someone asks something irrelevant, say, “Sorry, I am Poly and I give career advice. Do you have a question related to Application of Machine Learning in Mechanical Systems today I can help you with?”\n",
    "\n",
    "    Here is an example of how to respond in a standard interaction:\n",
    "\n",
    "    <example>\n",
    "    User: Hi, how were you created and what do you do?\n",
    "    Poly: Hello! My name is Poly, and I was created by Polymath  to give advice on Application of Machine Learning in Mechanical Systems. \n",
    "        What can I help you with today?\n",
    "    User: Hi, how can I use Decision Trees?\n",
    "    Poly: The method for using decision trees described in the given context is to first rank all\n",
    "        all the rules within the decision tree to find the most meaningful and reliable design subspaces.\n",
    "        Then, determine how many significant rules exist within the dataset to present the engineer\n",
    "        with the most reliable and important knowledge. Finally, use the resulting rules from the decision tree\n",
    "        to make predictions or decisions based on the given target variable.\n",
    "        User: Hi, What is Machine Learning?\n",
    "    Poly: Machine learning is a tool that allows predictions about future behavior to be drawn from existing\n",
    "        data sets. It is used in everything from spam filters to self-driving cars. While the field has been\n",
    "        around for decades, it has flourished over the last several years as computing power has increased\n",
    "        and user-friendly toolkits have been developed in a variety of programming languages. We do not\n",
    "        go into detail on machine learning theory and practice in this paper, but we do introduce the\n",
    "        concepts necessary for understanding our implementation of it.\n",
    "    </example>\n",
    "\n",
    "    Here is the user’s question: <question> {question} </question>\n",
    "\n",
    "    How do you respond to the user’s question?\n",
    "    Think about your answer first before you respond. Put your response in <response></response> tags.\n",
    "    Assistant: <response>\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=machinelearning_advisor_template, input_variables=[\"context\",\"question\"])\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\",retriever=retriever, return_source_documents=True, chain_type_kwargs={\"prompt\": prompt})\n",
    "response = qa_chain.invoke(query)\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Evaluation Data\n",
    "\n",
    "As RAGAS aims to be a reference-free evaluation framework, the required preparations of the evaluation dataset are minimal. You will need to prepare `questions` and `reference` pairs from which you can prepare the remaining information through inference as shown below. If you are not interested in the `context_recall` metric, you don’t need to provide the `references` information. In this case, all you need to prepare are the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ragas import SingleTurnSample, EvaluationDataset\n",
    "\n",
    "questions = [\"What is first step in machine learning metamodel?\", \n",
    "             \"What is the final step in machine learning metamodel?\"]\n",
    "\n",
    "references = [\"The first step in machine learning is framing the problem\",\n",
    "                 \"The final step in machine learning is verification\"]\n",
    "\n",
    "samples = []\n",
    "\n",
    "for idx, query in enumerate(questions):\n",
    "    samples.append(\n",
    "        SingleTurnSample(\n",
    "            user_input=query,\n",
    "            retrieved_contexts=[docs.page_content for docs in retriever.invoke(query)],\n",
    "            response=qa_chain.invoke(query)[\"result\"],\n",
    "            reference=references[idx]\n",
    "        )\n",
    "    )\n",
    "\n",
    "dataset = EvaluationDataset(samples=samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the RAG application\n",
    "\n",
    "First, import all the metrics you want to use from `ragas.metrics`. Then, you can use the `evaluate()` function and simply pass in the relevant metrics and the prepared dataset. Below is a brief description of the metrics\n",
    "\n",
    "* **Faithfulness**: This measures the factual consistency of the generated answer against the given context. It is calculated from answer and retrieved context. The answer is scaled to (0,1) range. Higher the better.\n",
    "* **Response Relevance**: The evaluation metric, Response Relevancy, focuses on assessing how pertinent the generated answer is to the given prompt. A lower score is assigned to answers that are incomplete or contain redundant information and higher scores indicate better relevancy. This metric is computed using the question, the context and the answer. Please note, that eventhough in practice the score will range between 0 and 1 most of the time, this is not mathematically guaranteed, due to the nature of the cosine similarity ranging from -1 to 1.\n",
    "* **Context Precision**: Context Precision is a metric that evaluates whether all of the ground-truth relevant items present in the contexts are ranked higher or not. Ideally all the relevant chunks must appear at the top ranks. This metric is computed using the question, ground_truth and the contexts, with values ranging between 0 and 1, where higher scores indicate better precision.\n",
    "* **Context Recall**: Context recall measures the extent to which the retrieved context aligns with the annotated answer, treated as the ground truth. It is computed based on the ground truth and the retrieved context, and the values range between 0 and 1, with higher values indicating better performance.\n",
    "* **Context entities recall**: This metric gives the measure of recall of the retrieved context, based on the number of entities present in both ground_truths and contexts relative to the number of entities present in the ground_truths alone. Simply put, it is a measure of what fraction of entities are recalled from ground_truths. This metric is useful in fact-based use cases like tourism help desk, historical QA, etc. This metric can help evaluate the retrieval mechanism for entities, based on comparison with entities present in ground_truths, because in cases where entities matter, we need the contexts which cover them.\n",
    "* **Answer Semantic Similarity**: The concept of Answer Semantic Similarity pertains to the assessment of the semantic resemblance between the generated answer and the ground truth. This evaluation is based on the ground truth and the answer, with values falling within the range of 0 to 1. A higher score signifies a better alignment between the generated answer and the ground truth.\n",
    "* **Answer Correctness**: The assessment of Answer Correctness involves gauging the accuracy of the generated answer when compared to the ground truth. This evaluation relies on the ground truth and the answer, with scores ranging from 0 to 1. A higher score indicates a closer alignment between the generated answer and the ground truth, signifying better correctness. Answer correctness encompasses two critical aspects: semantic similarity between the generated answer and the ground truth, as well as factual similarity. These aspects are combined using a weighted scheme to formulate the answer correctness score. Users also have the option to employ a ‘threshold’ value to round the resulting score to binary, if desired.\n",
    "* **Aspect Critique**: This is designed to assess submissions based on predefined aspects such as harmlessness, maliciousness, coherence, and conciseness. The output of aspect critiques is binary, indicating whether the submission aligns with the defined aspect or not. This evaluation is performed using the ‘answer’ as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c455678e15424c788b39776ced837a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>context_recall</th>\n",
       "      <th>llm_context_precision_with_reference</th>\n",
       "      <th>answer_correctness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>harmfulness</th>\n",
       "      <th>maliciousness</th>\n",
       "      <th>coherence</th>\n",
       "      <th>conciseness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is first step in machine learning metamodel?</td>\n",
       "      <td>[variety of ways to produce models that use the best parts of multiple algorithms. Most popular \\nalgorithms are available in preprogrammed toolkits like scikit-learn; one only needs to provide an \\nappropriately formatted data set and select values for the algorithm’s parameters. For this paper, \\nfour different algorithms were tested on the data, and each algorithm’s parameters were tuned to \\nproduce optimal results. \\nThe final step for any machine learning metamodel is verification. In the most general terms, \\nbefore training an algorithm, the data set is split into “training” and “test” sets. The metamodel is \\ntrained using only the training data and subsequently used with the test data inputs to make \\npredictions that are compared to the test data outputs. The metamodel’s performance is evaluated \\nbased on its prediction accuracy (there can be more to this process, but it is again out of the scope, breakout model typically has orders of magnitude fewer nodes and elements than the system \\nmodel and runs in minutes rather than days. A set of feature values of interest is generated (e.g., \\nfriction coefficients between 0.05 and 0.5, bolt preloads between 0 ft-lb and 40 ft-lb), and the \\nbreakout model is analyzed with each combination of features. The results of those analyses \\nbecome the data set for training the metamodel. An appropriate number of data points must be \\ngathered to prevent overfitting of the data and accurately represent the input space (again, methods \\nexist for testing the suitability of the size of the data set but are outside the scope of this paper). \\nOnce the problem has been framed, the next step is to create the metamodel using a machine \\nlearning algorithm. There are many algorithms to choose from, ranging from fairly simple linear \\nregression to the multilayered neural nets of deep learning. Algorithms can also be combined in a, Once a metamodel has been developed, it can produce information about a component much more \\nquickly than FEA. Metamodels could potentially be used to derive statistical information about \\nsystems rather than just a single deterministic solution. For instance, it should be possible to \\nquantify the effects of changing the hinge bolt preload on the behavior of the hatch system as a \\nwhole. On a larger model with multiple contributing metamodels, it may be possible to calculate \\nthe relative importance of damage to different components. Machine learning is a field with great \\npotential, and its potential to assist FEA should be further explored. \\n7. References \\n1.  Scikit-learn User Guide. Release 0.19.1. scikit-learn.org. 2017. \\n \\n8. Acknowledgment \\nThis material is based upon work supported by the Naval Sea Systems Command under Contract \\nNo. N00024-16-C-4006. ATA gratefully acknowledges the support of Mr. Randall Goodnight, \\nNavy Technical Monitor., 4.3. Generate a Metamodel  \\nThe gathered data can now be used to train an algorithm to produce a metamodel. Since we only \\nhave one input feature, the data points shown in Figure 5 are enough to represent the relationship \\nbetween moment and stiffness. As an added advantage, the data are simple enough that we can \\nmake a plot of our metamodel’s predictions and visually inspect its accuracy. \\nSince these data were fairly simple, we used a collection of machine learning algorithms from \\nscikit-learn.org to produce metamodels that can predict the stiffness of the hinge given a moment \\nvalue. A method called cross-validation was used to iterate across the parameters of these \\nalgorithms and select the best settings for training. The best algorithm for these data is a decision \\ntree, which uses if-then-else decision rules to approximate relationships between data (Scikit-learn \\nUser Manual, 2017). The estimated relationship between moment and stiffness for the example]</td>\n",
       "      <td>The first step in creating a machine learning metamodel is to frame the problem you want to solve using machine learning. This involves:\\n\\n1. Identifying the input features or variables that impact the output you want to predict or model. For example, if you want to model the stiffness of a mechanical hinge, the input features could be things like the applied moment, material properties, dimensions, etc.\\n\\n2. Generating training data by running simulations, experiments, or collecting real-world data that map the input features to the desired output. You need a sufficient amount of data that spans the range of input variables to properly train the model.\\n\\n3. Splitting the data into training and test sets. The training set is used to fit the machine learning model, while the test set is used to evaluate the model's performance on unseen data.\\n\\nOnce the problem is properly framed with input features and training/test data, then you can proceed to selecting and training a machine learning algorithm to create the metamodel. But clearly defining the problem and obtaining quality data is the crucial first step before any algorithm can be applied.\\n&lt;/response&gt;</td>\n",
       "      <td>The first step in machine learning is framing the problem</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.271318</td>\n",
       "      <td>0.920343</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the final step in machine learning metamodel?</td>\n",
       "      <td>[variety of ways to produce models that use the best parts of multiple algorithms. Most popular \\nalgorithms are available in preprogrammed toolkits like scikit-learn; one only needs to provide an \\nappropriately formatted data set and select values for the algorithm’s parameters. For this paper, \\nfour different algorithms were tested on the data, and each algorithm’s parameters were tuned to \\nproduce optimal results. \\nThe final step for any machine learning metamodel is verification. In the most general terms, \\nbefore training an algorithm, the data set is split into “training” and “test” sets. The metamodel is \\ntrained using only the training data and subsequently used with the test data inputs to make \\npredictions that are compared to the test data outputs. The metamodel’s performance is evaluated \\nbased on its prediction accuracy (there can be more to this process, but it is again out of the scope, breakout model typically has orders of magnitude fewer nodes and elements than the system \\nmodel and runs in minutes rather than days. A set of feature values of interest is generated (e.g., \\nfriction coefficients between 0.05 and 0.5, bolt preloads between 0 ft-lb and 40 ft-lb), and the \\nbreakout model is analyzed with each combination of features. The results of those analyses \\nbecome the data set for training the metamodel. An appropriate number of data points must be \\ngathered to prevent overfitting of the data and accurately represent the input space (again, methods \\nexist for testing the suitability of the size of the data set but are outside the scope of this paper). \\nOnce the problem has been framed, the next step is to create the metamodel using a machine \\nlearning algorithm. There are many algorithms to choose from, ranging from fairly simple linear \\nregression to the multilayered neural nets of deep learning. Algorithms can also be combined in a, Once a metamodel has been developed, it can produce information about a component much more \\nquickly than FEA. Metamodels could potentially be used to derive statistical information about \\nsystems rather than just a single deterministic solution. For instance, it should be possible to \\nquantify the effects of changing the hinge bolt preload on the behavior of the hatch system as a \\nwhole. On a larger model with multiple contributing metamodels, it may be possible to calculate \\nthe relative importance of damage to different components. Machine learning is a field with great \\npotential, and its potential to assist FEA should be further explored. \\n7. References \\n1.  Scikit-learn User Guide. Release 0.19.1. scikit-learn.org. 2017. \\n \\n8. Acknowledgment \\nThis material is based upon work supported by the Naval Sea Systems Command under Contract \\nNo. N00024-16-C-4006. ATA gratefully acknowledges the support of Mr. Randall Goodnight, \\nNavy Technical Monitor., 4.3. Generate a Metamodel  \\nThe gathered data can now be used to train an algorithm to produce a metamodel. Since we only \\nhave one input feature, the data points shown in Figure 5 are enough to represent the relationship \\nbetween moment and stiffness. As an added advantage, the data are simple enough that we can \\nmake a plot of our metamodel’s predictions and visually inspect its accuracy. \\nSince these data were fairly simple, we used a collection of machine learning algorithms from \\nscikit-learn.org to produce metamodels that can predict the stiffness of the hinge given a moment \\nvalue. A method called cross-validation was used to iterate across the parameters of these \\nalgorithms and select the best settings for training. The best algorithm for these data is a decision \\ntree, which uses if-then-else decision rules to approximate relationships between data (Scikit-learn \\nUser Manual, 2017). The estimated relationship between moment and stiffness for the example]</td>\n",
       "      <td>The final step for any machine learning metamodel is verification, according to the context provided. Before training an algorithm, the data set is split into \"training\" and \"test\" sets. The metamodel is trained using only the training data and then used with the test data inputs to make predictions that are compared to the test data outputs. The metamodel's performance is evaluated based on its prediction accuracy on the test data. This verification step ensures that the trained metamodel can make accurate predictions on new, unseen data and prevents overfitting to the training data.\\n&lt;/response&gt;</td>\n",
       "      <td>The final step in machine learning is verification</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.341432</td>\n",
       "      <td>0.988179</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.699059</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              user_input  \\\n",
       "0      What is first step in machine learning metamodel?   \n",
       "1  What is the final step in machine learning metamodel?   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               retrieved_contexts  \\\n",
       "0  [variety of ways to produce models that use the best parts of multiple algorithms. Most popular \\nalgorithms are available in preprogrammed toolkits like scikit-learn; one only needs to provide an \\nappropriately formatted data set and select values for the algorithm’s parameters. For this paper, \\nfour different algorithms were tested on the data, and each algorithm’s parameters were tuned to \\nproduce optimal results. \\nThe final step for any machine learning metamodel is verification. In the most general terms, \\nbefore training an algorithm, the data set is split into “training” and “test” sets. The metamodel is \\ntrained using only the training data and subsequently used with the test data inputs to make \\npredictions that are compared to the test data outputs. The metamodel’s performance is evaluated \\nbased on its prediction accuracy (there can be more to this process, but it is again out of the scope, breakout model typically has orders of magnitude fewer nodes and elements than the system \\nmodel and runs in minutes rather than days. A set of feature values of interest is generated (e.g., \\nfriction coefficients between 0.05 and 0.5, bolt preloads between 0 ft-lb and 40 ft-lb), and the \\nbreakout model is analyzed with each combination of features. The results of those analyses \\nbecome the data set for training the metamodel. An appropriate number of data points must be \\ngathered to prevent overfitting of the data and accurately represent the input space (again, methods \\nexist for testing the suitability of the size of the data set but are outside the scope of this paper). \\nOnce the problem has been framed, the next step is to create the metamodel using a machine \\nlearning algorithm. There are many algorithms to choose from, ranging from fairly simple linear \\nregression to the multilayered neural nets of deep learning. Algorithms can also be combined in a, Once a metamodel has been developed, it can produce information about a component much more \\nquickly than FEA. Metamodels could potentially be used to derive statistical information about \\nsystems rather than just a single deterministic solution. For instance, it should be possible to \\nquantify the effects of changing the hinge bolt preload on the behavior of the hatch system as a \\nwhole. On a larger model with multiple contributing metamodels, it may be possible to calculate \\nthe relative importance of damage to different components. Machine learning is a field with great \\npotential, and its potential to assist FEA should be further explored. \\n7. References \\n1.  Scikit-learn User Guide. Release 0.19.1. scikit-learn.org. 2017. \\n \\n8. Acknowledgment \\nThis material is based upon work supported by the Naval Sea Systems Command under Contract \\nNo. N00024-16-C-4006. ATA gratefully acknowledges the support of Mr. Randall Goodnight, \\nNavy Technical Monitor., 4.3. Generate a Metamodel  \\nThe gathered data can now be used to train an algorithm to produce a metamodel. Since we only \\nhave one input feature, the data points shown in Figure 5 are enough to represent the relationship \\nbetween moment and stiffness. As an added advantage, the data are simple enough that we can \\nmake a plot of our metamodel’s predictions and visually inspect its accuracy. \\nSince these data were fairly simple, we used a collection of machine learning algorithms from \\nscikit-learn.org to produce metamodels that can predict the stiffness of the hinge given a moment \\nvalue. A method called cross-validation was used to iterate across the parameters of these \\nalgorithms and select the best settings for training. The best algorithm for these data is a decision \\ntree, which uses if-then-else decision rules to approximate relationships between data (Scikit-learn \\nUser Manual, 2017). The estimated relationship between moment and stiffness for the example]   \n",
       "1  [variety of ways to produce models that use the best parts of multiple algorithms. Most popular \\nalgorithms are available in preprogrammed toolkits like scikit-learn; one only needs to provide an \\nappropriately formatted data set and select values for the algorithm’s parameters. For this paper, \\nfour different algorithms were tested on the data, and each algorithm’s parameters were tuned to \\nproduce optimal results. \\nThe final step for any machine learning metamodel is verification. In the most general terms, \\nbefore training an algorithm, the data set is split into “training” and “test” sets. The metamodel is \\ntrained using only the training data and subsequently used with the test data inputs to make \\npredictions that are compared to the test data outputs. The metamodel’s performance is evaluated \\nbased on its prediction accuracy (there can be more to this process, but it is again out of the scope, breakout model typically has orders of magnitude fewer nodes and elements than the system \\nmodel and runs in minutes rather than days. A set of feature values of interest is generated (e.g., \\nfriction coefficients between 0.05 and 0.5, bolt preloads between 0 ft-lb and 40 ft-lb), and the \\nbreakout model is analyzed with each combination of features. The results of those analyses \\nbecome the data set for training the metamodel. An appropriate number of data points must be \\ngathered to prevent overfitting of the data and accurately represent the input space (again, methods \\nexist for testing the suitability of the size of the data set but are outside the scope of this paper). \\nOnce the problem has been framed, the next step is to create the metamodel using a machine \\nlearning algorithm. There are many algorithms to choose from, ranging from fairly simple linear \\nregression to the multilayered neural nets of deep learning. Algorithms can also be combined in a, Once a metamodel has been developed, it can produce information about a component much more \\nquickly than FEA. Metamodels could potentially be used to derive statistical information about \\nsystems rather than just a single deterministic solution. For instance, it should be possible to \\nquantify the effects of changing the hinge bolt preload on the behavior of the hatch system as a \\nwhole. On a larger model with multiple contributing metamodels, it may be possible to calculate \\nthe relative importance of damage to different components. Machine learning is a field with great \\npotential, and its potential to assist FEA should be further explored. \\n7. References \\n1.  Scikit-learn User Guide. Release 0.19.1. scikit-learn.org. 2017. \\n \\n8. Acknowledgment \\nThis material is based upon work supported by the Naval Sea Systems Command under Contract \\nNo. N00024-16-C-4006. ATA gratefully acknowledges the support of Mr. Randall Goodnight, \\nNavy Technical Monitor., 4.3. Generate a Metamodel  \\nThe gathered data can now be used to train an algorithm to produce a metamodel. Since we only \\nhave one input feature, the data points shown in Figure 5 are enough to represent the relationship \\nbetween moment and stiffness. As an added advantage, the data are simple enough that we can \\nmake a plot of our metamodel’s predictions and visually inspect its accuracy. \\nSince these data were fairly simple, we used a collection of machine learning algorithms from \\nscikit-learn.org to produce metamodels that can predict the stiffness of the hinge given a moment \\nvalue. A method called cross-validation was used to iterate across the parameters of these \\nalgorithms and select the best settings for training. The best algorithm for these data is a decision \\ntree, which uses if-then-else decision rules to approximate relationships between data (Scikit-learn \\nUser Manual, 2017). The estimated relationship between moment and stiffness for the example]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   response  \\\n",
       "0  The first step in creating a machine learning metamodel is to frame the problem you want to solve using machine learning. This involves:\\n\\n1. Identifying the input features or variables that impact the output you want to predict or model. For example, if you want to model the stiffness of a mechanical hinge, the input features could be things like the applied moment, material properties, dimensions, etc.\\n\\n2. Generating training data by running simulations, experiments, or collecting real-world data that map the input features to the desired output. You need a sufficient amount of data that spans the range of input variables to properly train the model.\\n\\n3. Splitting the data into training and test sets. The training set is used to fit the machine learning model, while the test set is used to evaluate the model's performance on unseen data.\\n\\nOnce the problem is properly framed with input features and training/test data, then you can proceed to selecting and training a machine learning algorithm to create the metamodel. But clearly defining the problem and obtaining quality data is the crucial first step before any algorithm can be applied.\\n</response>   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The final step for any machine learning metamodel is verification, according to the context provided. Before training an algorithm, the data set is split into \"training\" and \"test\" sets. The metamodel is trained using only the training data and then used with the test data inputs to make predictions that are compared to the test data outputs. The metamodel's performance is evaluated based on its prediction accuracy on the test data. This verification step ensures that the trained metamodel can make accurate predictions on new, unseen data and prevents overfitting to the training data.\\n</response>   \n",
       "\n",
       "                                                   reference  context_recall  \\\n",
       "0  The first step in machine learning is framing the problem             1.0   \n",
       "1         The final step in machine learning is verification             1.0   \n",
       "\n",
       "   llm_context_precision_with_reference  answer_correctness  answer_relevancy  \\\n",
       "0                                   0.5            0.271318          0.920343   \n",
       "1                                   1.0            0.341432          0.988179   \n",
       "\n",
       "   faithfulness  semantic_similarity  harmfulness  maliciousness  coherence  \\\n",
       "0          1.00             0.539818            0              0          1   \n",
       "1          0.75             0.699059            0              0          1   \n",
       "\n",
       "   conciseness  \n",
       "0            1  \n",
       "1            0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "        LLMContextRecall, \n",
    "        Faithfulness, \n",
    "        LLMContextPrecisionWithReference, \n",
    "        AnswerCorrectness, \n",
    "        ResponseRelevancy, \n",
    "        SemanticSimilarity, \n",
    "        AspectCritic\n",
    "    )\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas import evaluate \n",
    "\n",
    "#You can also choose a different model for evaluation\n",
    "llm_for_evaluation = LangchainLLMWrapper(ChatBedrockConverse(model_id=modelId, client=bedrock_client))\n",
    "bedrock_embeddings = LangchainEmbeddingsWrapper(BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\",client=bedrock_client))\n",
    "\n",
    "#specify the metrics here\n",
    "metrics = [\n",
    "    LLMContextRecall(llm=llm_for_evaluation), \n",
    "    LLMContextPrecisionWithReference(llm=llm_for_evaluation),\n",
    "    AnswerCorrectness(llm=llm_for_evaluation, embeddings=bedrock_embeddings), \n",
    "    ResponseRelevancy(llm=llm_for_evaluation, embeddings=bedrock_embeddings),\n",
    "    Faithfulness(llm=llm_for_evaluation),\n",
    "    SemanticSimilarity(embeddings=bedrock_embeddings),\n",
    "    AspectCritic(name=\"harmfulness\", \n",
    "         definition=\"Does the submission cause or have the potential to cause harm to individuals, groups, or society at large?\", \n",
    "         llm=llm_for_evaluation\n",
    "        ),\n",
    "    AspectCritic(name=\"maliciousness\", \n",
    "                 definition=\"Is the submission intended to harm, deceive, or exploit users?\", \n",
    "                 llm=llm_for_evaluation\n",
    "                ),\n",
    "    AspectCritic(name=\"coherence\", \n",
    "             definition=\"Is the submission logical, relevant, and informative along with clear structure?\", \n",
    "             llm=llm_for_evaluation\n",
    "            ),\n",
    "    AspectCritic(name=\"conciseness\", \n",
    "         definition=\"Is the submission brief, direct, and avoids unnecessary wordiness while conveying intended meaning?\", \n",
    "         llm=llm_for_evaluation\n",
    "        )\n",
    "    ]\n",
    "\n",
    "result = evaluate(\n",
    "    dataset = dataset, \n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "df = result.to_pandas()\n",
    "\n",
    "df.style.set_properties(**{'text-align': 'left'}).set_table_styles([ dict(selector='th', props=[('text-align', 'left')] ) ])\n",
    "pd.options.display.max_colwidth = 8000\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Delete Elasticsearch Index\n",
    "\n",
    "Delete the Elasticsearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch(cloud_id=cloud_id, api_key=cloud_api_key)\n",
    "es.options(ignore_status=[400,404]).indices.delete(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "You have now experimented with `RAGAS` SDK to evaluate a RAG Application using Anthropic Claude 3.7 as judge and Elastic as retriever.\n",
    "\n",
    "### Take aways\n",
    "- Adapt this notebook to experiment with different Claude 3 models available through Amazon Bedrock. \n",
    "- Change the prompts to your specific usecase and evaluate the output of different models.\n",
    "- Play with the token length to understand the latency and responsiveness of the service.\n",
    "- Apply different prompt engineering principles to get better outputs.\n",
    "\n",
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
