{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c18a8a55-fc48-40be-be4b-8eae7507b3b4",
   "metadata": {},
   "source": [
    "# Create Bedrock Agents for Splunk AI Assistant with Function Definition\n",
    "\n",
    "In this notebook we will create an Agent for Splunk usecases in Amazon Bedrock using the new capabilities for function definition.\n",
    "\n",
    "We will create agents and functions in Amazon Bedrock for various use cases like getting Splunk sourcetypes for a given NLP question, getting the schema for the given source type, getting lookups and values for given source types and function to execute the SPL query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beee7935-28e5-40f1-9907-e59d2312ef8c",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Before starting, let's update the botocore and boto3 packages to ensure we have the latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a1c2e-3534-468c-9dc4-6f03100a4b0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade -q botocore\n",
    "!python3 -m pip install --upgrade -q boto3\n",
    "!python3 -m pip install --upgrade -q awscli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143a6e2-4458-42ca-bbe7-157ff364d41a",
   "metadata": {},
   "source": [
    "Let's now check the boto3 version to ensure the correct version has been installed. Your version should be greater than or equal to 1.34.90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d00833b-00cb-43e4-b603-d941c3003f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import zipfile\n",
    "from io import BytesIO\n",
    "import uuid\n",
    "import pprint\n",
    "import logging\n",
    "print(boto3.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160f8d06-aea4-4675-ae9b-346a92ec4b3c",
   "metadata": {},
   "source": [
    "Let's now create the boto3 clients for the required AWS services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0691190-6610-46d0-922b-16d06684f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting boto3 clients for required AWS services\n",
    "sts_client = boto3.client('sts')\n",
    "iam_client = boto3.client('iam')\n",
    "lambda_client = boto3.client('lambda')\n",
    "bedrock_agent_client = boto3.client('bedrock-agent')\n",
    "bedrock_agent_runtime_client = boto3.client('bedrock-agent-runtime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d22d0d6-7dfb-40e9-918d-b139fa9938a8",
   "metadata": {},
   "source": [
    "Next we can set some configuration variables for the agent and for the lambda function being created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f9ac74-5d35-460c-9005-8373713a4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region, account_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db4fb523-a114-47b9-a5cc-451880a88c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration variables\n",
    "suffix = f\"{region}-{account_id}\"\n",
    "agent_name = \"splunk-chatbot-agent\"\n",
    "agent_bedrock_allow_policy_name = f\"{agent_name}-ba-{suffix}\"\n",
    "agent_role_name = f'AmazonBedrockExecutionRoleForAgents_{agent_name}'\n",
    "agent_foundation_model = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "agent_description = \"Security Agent for querying Splunk and execute SPL Queries\"\n",
    "agent_instruction = \"You are a Splunk chatbot agent, helping security analysts to write efficient Splunk \\\n",
    "SPL queries and execute them to analyze the results. You need to understand the schema of Splunk sourcetypes \\\n",
    "to write efficient SPL queries.\"\n",
    "agent_action_group_name = \"SplunkQueryAgentGroup\"\n",
    "agent_action_group_description = \"Actions for writing efficient SPL queries for AWS data sources and interpret the results\"\n",
    "agent_alias_name = f\"{agent_name}-alias\"\n",
    "lambda_function_role = f'{agent_name}-lambda-role-{suffix}'\n",
    "lambda_function_name = f'{agent_name}-{suffix}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fe9a05",
   "metadata": {},
   "source": [
    "Replace with secret ARN you created as part of the pre-requisite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97128244",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_arn=\"arn:aws:secretsmanager:AWS-REGION:AWS-ACCOUNTID:secret:SECRET-NAME\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524b093-02fb-451f-aa51-0a544f127a1d",
   "metadata": {},
   "source": [
    "## Prepare RAG VectorDB for AWS source types\n",
    "In this step we will create Embeddings for AWS source types and store it in OpenSearch VectorDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "24f3a0b4-9c0a-45dd-b091-dde105ab90cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the clients\n",
    "opensearchserverless_client = boto3.client('opensearchserverless')\n",
    "sts_client = boto3.client('sts')\n",
    "connected_role = sts_client.get_caller_identity()['Arn'].split('/')[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df43ee7-2c93-4adf-8e21-b1c67037f9df",
   "metadata": {},
   "source": [
    "Lets create functions and policies for OpenSearch serverless and create the collections to store embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d406ad7-17e4-4404-b1af-0c491403120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_collection(collection_name):\n",
    "    try:\n",
    "        response = opensearchserverless_client.create_collection(\n",
    "            name=collection_name,\n",
    "            description='Vector search collection',\n",
    "            type='VECTORSEARCH'\n",
    "        )\n",
    "        print(f\"Vector collection creation initiated: {response['createCollectionDetail']['name']}\")\n",
    "        return response['createCollectionDetail']['id']\n",
    "    except opensearchserverless_client.exceptions.ConflictException:\n",
    "        print(f\"Collection {collection_name} already exists.\")\n",
    "        collections = opensearchserverless_client.list_collections()['collectionSummaries']\n",
    "        return next((c['id'] for c in collections if c['name'] == collection_name), None)\n",
    "\n",
    "def wait_for_collection_creation(collection_id):\n",
    "    while True:\n",
    "        response = opensearchserverless_client.batch_get_collection(ids=[collection_id])\n",
    "        status = response['collectionDetails'][0]['status']\n",
    "        if status == 'ACTIVE':\n",
    "            print(\"Collection is now active.\")\n",
    "            return response['collectionDetails'][0]['collectionEndpoint']\n",
    "        elif status in ['FAILED', 'DELETED']:\n",
    "            raise Exception(f\"Collection creation failed with status: {status}\")\n",
    "        print(\"Waiting for collection to become active...\")\n",
    "        time.sleep(60)\n",
    "\n",
    "def create_access_policy(collection_name):\n",
    "    policy_name = f\"{collection_name}-access-policy\"\n",
    "    account_id = sts_client.get_caller_identity()['Account']\n",
    "    policy_document = [{\n",
    "        \"Description\": f\"Access policy for {collection_name}\",\n",
    "        \"Rules\": [\n",
    "            {\n",
    "                \"ResourceType\": \"index\",\n",
    "                \"Resource\": [f\"index/{collection_name}/*\"],\n",
    "                \"Permission\": [\n",
    "                    \"aoss:CreateIndex\",\n",
    "                    \"aoss:DeleteIndex\",\n",
    "                    \"aoss:UpdateIndex\",\n",
    "                    \"aoss:DescribeIndex\",\n",
    "                    \"aoss:ReadDocument\",\n",
    "                    \"aoss:WriteDocument\"\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"ResourceType\": \"collection\",\n",
    "                \"Resource\": [f\"collection/{collection_name}\"],\n",
    "                \"Permission\": [\n",
    "                    \"aoss:CreateCollectionItems\",\n",
    "                    \"aoss:DeleteCollectionItems\",\n",
    "                    \"aoss:UpdateCollectionItems\"\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"Principal\": [\n",
    "            f\"arn:aws:iam::{account_id}:role/{connected_role}\",\n",
    "            f\"arn:aws:iam::{account_id}:role/{lambda_function_role}\"\n",
    "        ]\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = opensearchserverless_client.create_access_policy(\n",
    "            name=policy_name,\n",
    "            type='data',\n",
    "            policy=json.dumps(policy_document)\n",
    "        )\n",
    "        print(f\"Access policy created: {response['accessPolicyDetail']['name']}\")\n",
    "    except opensearchserverless_client.exceptions.ConflictException:\n",
    "        print(f\"Access policy {policy_name} already exists.\")\n",
    "\n",
    "def create_encryption_policy(collection_name):\n",
    "    policy_name = f\"{collection_name}-encryption-policy\"\n",
    "    policy_document = {\n",
    "        \"Rules\": [\n",
    "            {\n",
    "                \"ResourceType\": \"collection\",\n",
    "                \"Resource\": [f\"collection/{collection_name}\"]\n",
    "            }\n",
    "        ],\n",
    "        \"AWSOwnedKey\": True\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = opensearchserverless_client.create_security_policy(\n",
    "            name=policy_name,\n",
    "            policy=json.dumps(policy_document),\n",
    "            type='encryption'\n",
    "        )\n",
    "        print(f\"Encryption policy created: {response['securityPolicyDetail']['name']}\")\n",
    "    except opensearchserverless_client.exceptions.ConflictException:\n",
    "        print(f\"Encryption policy {policy_name} already exists.\")\n",
    "\n",
    "def create_network_policy(collection_name):\n",
    "    policy_name = f\"{collection_name}-network-policy\"\n",
    "    policy_document = [{\n",
    "        \"Rules\": [\n",
    "            {\n",
    "                \"ResourceType\": \"collection\",\n",
    "                \"Resource\": [f\"collection/{collection_name}\"]\n",
    "            },\n",
    "            {\n",
    "                \"ResourceType\": \"dashboard\",\n",
    "                \"Resource\": [f\"collection/{collection_name}\"]\n",
    "            }\n",
    "        ],\n",
    "        \"AllowFromPublic\": True\n",
    "    }]\n",
    "\n",
    "    try:\n",
    "        response = opensearchserverless_client.create_security_policy(\n",
    "            name=policy_name,\n",
    "            policy=json.dumps(policy_document),\n",
    "            type='network'\n",
    "        )\n",
    "        print(f\"Network policy created: {response['securityPolicyDetail']['name']}\")\n",
    "    except opensearchserverless_client.exceptions.ConflictException:\n",
    "        print(f\"Network policy {policy_name} already exists.\")\n",
    "\n",
    "# Usage\n",
    "collection_name = 'splunk-vector'\n",
    "\n",
    "# Create the encryption policy\n",
    "create_encryption_policy(collection_name)\n",
    "\n",
    "# Create the network policy\n",
    "create_network_policy(collection_name)\n",
    "\n",
    "# Create the vector collection\n",
    "collection_id = create_vector_collection(collection_name)\n",
    "\n",
    "# Wait for the collection to become active\n",
    "endpoint = wait_for_collection_creation(collection_id)\n",
    "\n",
    "# Create the access policy\n",
    "create_access_policy(collection_name)\n",
    "\n",
    "print(f\"Vector collection endpoint: {endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5bf823-c508-430f-8691-69ca88350dd7",
   "metadata": {},
   "source": [
    "### Create Embeddings and load into opensearch serverless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca8ee4c-4d96-439e-936c-ac0937eb76e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install opensearch-py\n",
    "!pip install requests_aws4auth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a677f5e6-4857-41c2-93d2-59579c1b6a26",
   "metadata": {},
   "source": [
    "Initialize client for bedrock runtime and OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "421f444f-afaa-4d44-9f1a-8b3b69ee33c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "\n",
    "# Initialize clients\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name=region)\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,\n",
    "                   region, \"aoss\", session_token=credentials.token)\n",
    "aoss_host = endpoint.replace(\"https://\", \"\")\n",
    "# Initialize OpenSearch client\n",
    "opensearch_client = OpenSearch(\n",
    "    hosts=[{'host': aoss_host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    timeout=300, \n",
    "    max_retries=10, \n",
    "    retry_on_timeout=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3405ac-7e29-4d9a-9588-f53321e564f8",
   "metadata": {},
   "source": [
    "create the index in OpenSearch and load the sourcetype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "acdc36fe-0ae2-4786-832a-3a690acb0963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_name = 'splunk-sourcetypes'\n",
    "def create_index_if_not_exists():\n",
    "    if not opensearch_client.indices.exists(index=index_name):\n",
    "        index_body = {\n",
    "          'settings': {\n",
    "              'index': {\n",
    "                  'knn': True,\n",
    "              }\n",
    "          },\n",
    "          'mappings': {\n",
    "              'properties': {\n",
    "                  'my_vector': {\n",
    "                      'type': 'knn_vector',\n",
    "                      'dimension': 1024,  # Dimension of the Titan embedding \n",
    "                      \"method\": {\n",
    "                        \"name\": \"hnsw\",\n",
    "                        \"space_type\": \"l2\",  # Or \"cosinesimil\" for cosine similarity\n",
    "                        \"engine\": \"faiss\",  # Or \"faiss\"\n",
    "                        \"parameters\": {\n",
    "                            \"ef_construction\": 128,\n",
    "                            \"m\": 24\n",
    "                        }              \n",
    "                  }\n",
    "                },\n",
    "\n",
    "                  'content': {'type': 'text'}\n",
    "\n",
    "          }\n",
    "        }\n",
    "        }\n",
    "        opensearch_client.indices.create(index=index_name, body=index_body)\n",
    "        print(f\"Created index: {index_name}\")\n",
    "\n",
    "def generate_embedding(text):\n",
    "    body = json.dumps({\"inputText\": text})\n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body,\n",
    "        modelId='amazon.titan-embed-text-v2:0',\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    return response_body['embedding']\n",
    "\n",
    "def process_csv_file(file_path):\n",
    "    create_index_if_not_exists()\n",
    "    with open(file_path, 'r', encoding='utf-8-sig') as data:\n",
    "      for line in csv.DictReader(data):\n",
    "        embedding = generate_embedding(json.dumps(line).replace('\\\\u00a0', ' '))\n",
    "        # Prepare document\n",
    "        doc = {\n",
    "            'content': json.dumps(line).replace('\\\\u00a0', ' '),\n",
    "            'my_vector': embedding\n",
    "        }\n",
    "        # Index the document\n",
    "        print(doc['content'])\n",
    "        response = opensearch_client.index(index=index_name, body=doc)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297cb51-9efc-49fd-aa48-4d1080adf319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usage\n",
    "csv_file_path = 'data/aws-source-types.csv'\n",
    "process_csv_file(csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36813589-f2be-4c14-8d24-70a8ea67ddd7",
   "metadata": {},
   "source": [
    "Create a function to do an approximate search for a query and verify results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b94d53-951a-4821-b1f0-41364b7caabf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_similar_documents(query):\n",
    "    query_embedding = generate_embedding(query)\n",
    "    response = opensearch_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"my_vector\": {\n",
    "                        \"vector\": query_embedding,\n",
    "                        \"k\": 1  # Return the top 3 most relevant documents\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    # return response\n",
    "    if response['hits']['hits']:\n",
    "        return [item['_source']['content'] for item in response['hits']['hits']]\n",
    "    else:\n",
    "        return \"No sourcetypes found\"\n",
    "\n",
    "# Example user query\n",
    "user_query = \"VPC FlowLogs\"\n",
    "relevant_documents = retrieve_similar_documents(user_query)\n",
    "relevant_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e4972c-5273-43f6-b8a7-30040781783e",
   "metadata": {},
   "source": [
    "## Creating Lambda function\n",
    "Now that we created a Vector DB for the embeddings for AWS source types, lets now build a lambda functions to query these embeddings as well as other functions for Splunk's use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd6d600-c815-4ac3-9dc8-20256d749a5f",
   "metadata": {},
   "source": [
    "Install the libraries for lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46e7f57-ee58-450a-b71e-15595dfcf9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install splunk_sdk --target ./lambda_package/\n",
    "!pip install opensearch-py --target ./lambda_package/\n",
    "!pip install requests_aws4auth --target ./lambda_package/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b662cf94-d4f2-44e1-8ba2-d58374bfa3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./lambda_package/lambda_function.py\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "from time import sleep\n",
    "import splunklib.client as splunk_client\n",
    "import splunklib.results as results\n",
    "import boto3\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection\n",
    "from requests_aws4auth import AWS4Auth\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name=region)\n",
    "index_name = os.environ['aoss_index']\n",
    "# Initialize clients\n",
    "bedrock_client = boto3.client('bedrock-runtime', region_name=region)\n",
    "credentials = boto3.Session().get_credentials()\n",
    "awsauth = AWS4Auth(credentials.access_key, credentials.secret_key,\n",
    "                   region, \"aoss\", session_token=credentials.token)\n",
    "endpoint = os.environ['aoss_endpoint']\n",
    "aoss_host = endpoint.replace(\"https://\", \"\")\n",
    "# Initialize OpenSearch client\n",
    "opensearch_client = OpenSearch(\n",
    "    hosts=[{'host': aoss_host, 'port': 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    timeout=300, \n",
    "    max_retries=10, \n",
    "    retry_on_timeout=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection\n",
    ")\n",
    "\n",
    "def generate_embedding(text):    \n",
    "    body = json.dumps({\"inputText\": text})\n",
    "    response = bedrock_client.invoke_model(\n",
    "        body=body,\n",
    "        modelId='amazon.titan-embed-text-v2:0',\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "    response_body = json.loads(response['body'].read())\n",
    "    return response_body['embedding']\n",
    "\n",
    "def search_aws_sourcetypes(awssourcetype: str) ->str:\n",
    "    query_embedding = generate_embedding(awssourcetype)\n",
    "    response = opensearch_client.search(\n",
    "        index=index_name,\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"knn\": {\n",
    "                    \"my_vector\": {\n",
    "                        \"vector\": query_embedding,\n",
    "                        \"k\": 1  # Return the top 3 most relevant documents\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    # return response\n",
    "    if response['hits']['hits']:\n",
    "        return [item['_source']['content'] for item in response['hits']['hits']]\n",
    "    else:\n",
    "        return \"No sourcetypes found\"    \n",
    "def get_splunk_fields(sourcetype: str) ->str:\n",
    "    \"\"\"\n",
    "    Gets Splunk sourcetype as input and returns the list of fields in the sourcetype. Give the input sourcetype as only input string parameter. \n",
    "    This tool is useful to know which fields are stored in sourcetype to be used in SPL Queries. \n",
    "    \"\"\"\n",
    "    # Create a Secrets Manager client\n",
    "    secrets_client = boto3.client('secretsmanager')\n",
    "    secret_arn = os.environ['secret_arn']\n",
    "    response = secrets_client.get_secret_value(SecretId=secret_arn)\n",
    "    secret = json.loads(response['SecretString'])\n",
    "    splunkToken = secret['SplunkToken']\n",
    "    HOST=secret['SplunkHost']\n",
    "    PORT = 8089\n",
    "    # Create a Secrets Manager client and retrieve Splunk Secrets\n",
    "    service = splunk_client.connect(\n",
    "        host=HOST,\n",
    "        port=PORT,\n",
    "        splunkToken=splunkToken)\n",
    "        # username=USERNAME,\n",
    "        # password=PASSWORD)\n",
    "\n",
    "    # Create search Query\n",
    "    search_query = \"search index=main \"+ \"sourcetype=\"+sourcetype+\" | fieldsummary | fields field\"\n",
    "    # Create the search job\n",
    "\n",
    "    kwargs_normalsearch = {\"exec_mode\": \"normal\", \"earliest_time\": \"-15m\"}\n",
    "    job = service.jobs.create(search_query, **kwargs_normalsearch)\n",
    "    # Wait for the search to complete\n",
    "    while True:\n",
    "        print(job.is_ready())\n",
    "        while not job.is_ready():\n",
    "            pass\n",
    "        stats = {\"isDone\": job[\"isDone\"],\n",
    "                 \"doneProgress\": float(job[\"doneProgress\"])*100,\n",
    "                  \"scanCount\": int(job[\"scanCount\"]),\n",
    "                  \"eventCount\": int(job[\"eventCount\"]),\n",
    "                  \"resultCount\": int(job[\"resultCount\"])}\n",
    "    \n",
    "        status = (\"\\r%(doneProgress)03.1f%%   %(scanCount)d scanned   \"\n",
    "                  \"%(eventCount)d matched   %(resultCount)d results\") % stats\n",
    "    \n",
    "        sys.stdout.write(status)\n",
    "        sys.stdout.flush()\n",
    "        if stats[\"isDone\"] == \"1\":\n",
    "            sys.stdout.write(\"\\n\\nDone!\\n\\n\")\n",
    "            break\n",
    "        sleep(2)\n",
    "    fields = []        \n",
    "    print(status)\n",
    "    for result in results.JSONResultsReader(job.results(output_mode='json')):\n",
    "        fields.append(result['field'])\n",
    "    # return results.JSONResultsReader(job.results(output_mode='json'))\n",
    "    # fields = job.results()\n",
    "    # print(fields)\n",
    "    # fields = [field[\"field\"] for field in fields]\n",
    "    return fields\n",
    "\n",
    "def get_splunk_results(search_query:str) ->str:\n",
    "    \"\"\"\n",
    "    Executes a Splunk search query and returns the results as JSON data. Give the input search query as string variable.\n",
    "    Dont give any search values within quotes unless there is a space in the values.\n",
    "    Here is an example of search query:\n",
    "    search index=main sourcetype=aws:cloudtrail errorCode!=success | stats count by eventSource, eventName, errorCode | sort - count\n",
    "    \"\"\"\n",
    "    # Create a Secrets Manager client and retrieve Splunk Secrets\n",
    "    secrets_client = boto3.client('secretsmanager')\n",
    "    secret_arn = os.environ['secret_arn']\n",
    "    response = secrets_client.get_secret_value(SecretId=secret_arn)\n",
    "    secret = json.loads(response['SecretString'])\n",
    "    splunkToken = secret['SplunkToken']\n",
    "    HOST=secret['SplunkHost']\n",
    "    PORT = 8089\n",
    "\n",
    "\n",
    "    # Create a Service instance and log in\n",
    "    service = splunk_client.connect(\n",
    "        host=HOST,\n",
    "        port=PORT,\n",
    "        splunkToken=splunkToken)\n",
    "        # username=USERNAME,\n",
    "        # password=PASSWORD)\n",
    "\n",
    "    kwargs_normalsearch = {\"exec_mode\": \"normal\", \"earliest_time\": \"-24h\"}\n",
    "    job = service.jobs.create(search_query, **kwargs_normalsearch)\n",
    "\n",
    "    # Wait for the search to complete\n",
    "    while True:\n",
    "        while not job.is_ready():\n",
    "            pass\n",
    "        stats = {\"isDone\": job[\"isDone\"],\n",
    "                 \"doneProgress\": float(job[\"doneProgress\"])*100,\n",
    "                  \"scanCount\": int(job[\"scanCount\"]),\n",
    "                  \"eventCount\": int(job[\"eventCount\"]),\n",
    "                  \"resultCount\": int(job[\"resultCount\"])}\n",
    "\n",
    "        status = (\"\\r%(doneProgress)03.1f%%   %(scanCount)d scanned   \"\n",
    "                  \"%(eventCount)d matched   %(resultCount)d results\") % stats\n",
    "\n",
    "        # sys.stdout.write(status)\n",
    "        sys.stdout.flush()\n",
    "        if stats[\"isDone\"] == \"1\":\n",
    "            # sys.stdout.write(\"\\n\\nDone!\\n\\n\")\n",
    "            break\n",
    "        sleep(2)\n",
    "    # results = job.results(output_mode='json_cols')\n",
    "    # Get the results and return them as a JSON object\n",
    "    results_reader = results.JSONResultsReader(job.results(output_mode=\"json\"))\n",
    "    job.cancel()\n",
    "    return list(results_reader)\n",
    "\n",
    "\n",
    "\n",
    "def get_splunk_lookups(sourcetype: str) ->str:\n",
    "    \"\"\"\n",
    "    Gets Splunk sourcetype as input and returns the list of lookup values for the sourcetype. Useful when the initial SPL query do not return \n",
    "    any results due to a lookup field(s). This function gets all lookup names for a given sourcetype which the agent can use to get the right \n",
    "    lookup values for SPL query by calling the agent get_splunk_lookup_values. \n",
    "    \"\"\"\n",
    "    # Create a Secrets Manager client\n",
    "    secrets_client = boto3.client('secretsmanager')\n",
    "    secret_arn = os.environ['secret_arn']\n",
    "    response = secrets_client.get_secret_value(SecretId=secret_arn)\n",
    "    secret = json.loads(response['SecretString'])\n",
    "    splunkToken = secret['SplunkToken']\n",
    "    HOST=secret['SplunkHost']\n",
    "    PORT = 8089\n",
    "    # Create a Secrets Manager client and retrieve Splunk Secrets\n",
    "    service = splunk_client.connect(\n",
    "        host=HOST,\n",
    "        port=PORT,\n",
    "        splunkToken=splunkToken)\n",
    "\n",
    "\n",
    "    # Create 1st Query to get all lookup values for the source type.\n",
    "    search_query = \"| rest /servicesNS/-/-/data/props/lookups | search stanza=\"+sourcetype+\" \\\n",
    "    | dedup transform | fields transform\"\n",
    "    # Create the search job\n",
    "\n",
    "    kwargs_normalsearch = {\"exec_mode\": \"normal\", \"earliest_time\": \"-15m\"}\n",
    "    job = service.jobs.create(search_query, **kwargs_normalsearch)\n",
    "    # Wait for the search to complete\n",
    "    while True:\n",
    "        print(job.is_ready())\n",
    "        while not job.is_ready():\n",
    "            pass\n",
    "        stats = {\"isDone\": job[\"isDone\"],\n",
    "                 \"doneProgress\": float(job[\"doneProgress\"])*100,\n",
    "                  \"scanCount\": int(job[\"scanCount\"]),\n",
    "                  \"eventCount\": int(job[\"eventCount\"]),\n",
    "                  \"resultCount\": int(job[\"resultCount\"])}\n",
    "    \n",
    "        status = (\"\\r%(doneProgress)03.1f%%   %(scanCount)d scanned   \"\n",
    "                  \"%(eventCount)d matched   %(resultCount)d results\") % stats\n",
    "    \n",
    "        sys.stdout.write(status)\n",
    "        sys.stdout.flush()\n",
    "        if stats[\"isDone\"] == \"1\":\n",
    "            sys.stdout.write(\"\\n\\nDone!\\n\\n\")\n",
    "            break\n",
    "        sleep(2)\n",
    "    fields = []        \n",
    "    print(status)\n",
    "    print(job.results(output_mode='json'))\n",
    "    for result in results.JSONResultsReader(job.results(output_mode='json')):\n",
    "        fields.append(result['transform'])\n",
    "    if not fields:\n",
    "        fields.append(\"No lookups found for sourcetype \"+sourcetype)\n",
    "        return fields\n",
    "    return fields        \n",
    "\n",
    "def get_splunk_lookup_values(lookup_name: str) ->str:\n",
    "    \"\"\"\n",
    "    Gets Splunk lookup name as input and returns the lookup values. Useful when the initial SPL query do not return \n",
    "    any results due to a lookup field(s). This function gets all look up values for a given sourcetype which can be useful to rewrite the SPL queries\n",
    "    with appropriate lookup values. \n",
    "    \"\"\"\n",
    "    # Create a Secrets Manager client\n",
    "    secrets_client = boto3.client('secretsmanager')\n",
    "    secret_arn = os.environ['secret_arn']\n",
    "    response = secrets_client.get_secret_value(SecretId=secret_arn)\n",
    "    secret = json.loads(response['SecretString'])\n",
    "    splunkToken = secret['SplunkToken']\n",
    "    HOST=secret['SplunkHost']\n",
    "    PORT = 8089\n",
    "    # Create a Secrets Manager client and retrieve Splunk Secrets\n",
    "    service = splunk_client.connect(\n",
    "        host=HOST,\n",
    "        port=PORT,\n",
    "        splunkToken=splunkToken)\n",
    "\n",
    "\n",
    "    # Create 1st Query to get all lookup values for the source type.\n",
    "    search_query = \"| inputlookup \"+ lookup_name\n",
    "    # Create the search job\n",
    "\n",
    "    kwargs_normalsearch = {\"exec_mode\": \"normal\", \"earliest_time\": \"-15m\"}\n",
    "    job = service.jobs.create(search_query, **kwargs_normalsearch)\n",
    "    # Wait for the search to complete\n",
    "    while True:\n",
    "        print(job.is_ready())\n",
    "        while not job.is_ready():\n",
    "            pass\n",
    "        stats = {\"isDone\": job[\"isDone\"],\n",
    "                 \"doneProgress\": float(job[\"doneProgress\"])*100,\n",
    "                  \"scanCount\": int(job[\"scanCount\"]),\n",
    "                  \"eventCount\": int(job[\"eventCount\"]),\n",
    "                  \"resultCount\": int(job[\"resultCount\"])}\n",
    "    \n",
    "        status = (\"\\r%(doneProgress)03.1f%%   %(scanCount)d scanned   \"\n",
    "                  \"%(eventCount)d matched   %(resultCount)d results\") % stats\n",
    "    \n",
    "        sys.stdout.write(status)\n",
    "        sys.stdout.flush()\n",
    "        if stats[\"isDone\"] == \"1\":\n",
    "            sys.stdout.write(\"\\n\\nDone!\\n\\n\")\n",
    "            break\n",
    "        sleep(2)\n",
    "    #print(status)\n",
    "    print(job.results(output_mode=\"json\"))\n",
    "    # Get the results and return them as a list\n",
    "    fields = []\n",
    "    for result in results.JSONResultsReader(job.results(output_mode='json')):\n",
    "        print(result)\n",
    "        if re.search('ERROR', str(result)):\n",
    "            fields.append(\"No lookup values found for lookup name \"+lookup_name)\n",
    "            return fields\n",
    "        elif re.search('INFO', str(result)):\n",
    "            continue\n",
    "        fields.append(result)\n",
    "    if not fields:\n",
    "        fields.append(\"No lookup values found for lookup name \"+lookup_name)\n",
    "        return fields\n",
    "    return fields  \n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    ip = requests.get('https://checkip.amazonaws.com').text.strip()\n",
    "    print(\"Extern IP:\",ip)\n",
    "    print(\"*********Printing event data *************\")\n",
    "    print(event)\n",
    "    agent = event['agent']\n",
    "    actionGroup = event['actionGroup']\n",
    "    function = event['function']\n",
    "    parameters = event.get('parameters', [])\n",
    "    responseBody =  {\n",
    "        \"TEXT\": {\n",
    "            \"body\": \"Error, no function was called\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if function == 'search_aws_sourcetypes':\n",
    "        aws_sourcetype = None\n",
    "        for param in parameters:\n",
    "            if param[\"name\"] == \"awssourcetype\":\n",
    "                aws_sourcetype = param[\"value\"]\n",
    "        if not aws_sourcetype:\n",
    "            raise Exception(\"Missing mandatory parameter: awssourcetype\")\n",
    "        aws_sourcetype = search_aws_sourcetypes(aws_sourcetype)\n",
    "        print(type(json.dumps(aws_sourcetype)))\n",
    "        responseBody =  {\n",
    "            'TEXT': {\n",
    "                \"body\": json.dumps(aws_sourcetype)\n",
    "            }\n",
    "        }\n",
    "    elif function == 'get_splunk_fields':\n",
    "        sourcetype = None\n",
    "        for param in parameters:\n",
    "            if param[\"name\"] == \"sourcetype\":\n",
    "                sourcetype = param[\"value\"]\n",
    "        if not sourcetype:\n",
    "            raise Exception(\"Missing mandatory parameter: sourcetype\")      \n",
    "        sourcetype_fields = get_splunk_fields(sourcetype)\n",
    "        responseBody =  {\n",
    "            'TEXT': {\n",
    "                \"body\": json.dumps(sourcetype_fields)\n",
    "            }\n",
    "        }        \n",
    "    elif function == 'get_splunk_results':\n",
    "        search_query = None\n",
    "        for param in parameters:\n",
    "            if param[\"name\"] == \"search_query\":\n",
    "                search_query = param[\"value\"]\n",
    "        if not search_query:\n",
    "            raise Exception(\"Missing mandatory parameter: search_query\")      \n",
    "        query_results = get_splunk_results(search_query)\n",
    "        responseBody =  {\n",
    "            'TEXT': {\n",
    "                \"body\": json.dumps(query_results)\n",
    "            }\n",
    "        }         \n",
    "\n",
    "    elif function == 'get_splunk_lookups':\n",
    "        sourcetype = None\n",
    "        for param in parameters:\n",
    "            if param[\"name\"] == \"sourcetype\":\n",
    "                sourcetype = param[\"value\"]\n",
    "        if not sourcetype:\n",
    "            raise Exception(\"Missing mandatory parameter: sourcetype\")      \n",
    "        sourcetype_fields = get_splunk_lookups(sourcetype)\n",
    "        responseBody =  {\n",
    "            'TEXT': {\n",
    "                \"body\": json.dumps(sourcetype_fields)\n",
    "            }\n",
    "        }  \n",
    "\n",
    "    elif function == 'get_splunk_lookup_values':\n",
    "        lookup_name = None\n",
    "        for param in parameters:\n",
    "            if param[\"name\"] == \"lookup_name\":\n",
    "                lookup_name = param[\"value\"]\n",
    "        if not lookup_name:\n",
    "            raise Exception(\"Missing mandatory parameter: lookup_name\")      \n",
    "        lookup_values = get_splunk_lookup_values(lookup_name)\n",
    "        print(\"lookup values type\",type(lookup_values))\n",
    "        responseBody =  {\n",
    "            'TEXT': {\n",
    "                \"body\": json.dumps(lookup_values)\n",
    "            }\n",
    "        } \n",
    "\n",
    "\n",
    "    action_response = {\n",
    "        'actionGroup': actionGroup,\n",
    "        'function': function,\n",
    "        'functionResponse': {\n",
    "            'responseBody': responseBody\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "    function_response = {'response': action_response, 'messageVersion': event['messageVersion']}\n",
    "    print(\"Response: {}\".format(function_response))\n",
    "\n",
    "    return function_response                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf6fc85-781e-4184-96c6-f9c21998153d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create IAM Role for the Lambda function\n",
    "try:\n",
    "    assume_role_policy_document = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"lambda.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"sts:AssumeRole\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    assume_role_policy_document_json = json.dumps(assume_role_policy_document)\n",
    "\n",
    "    lambda_iam_role = iam_client.create_role(\n",
    "        RoleName=lambda_function_role,\n",
    "        AssumeRolePolicyDocument=assume_role_policy_document_json\n",
    "    )\n",
    "\n",
    "    # Pause to make sure role is created\n",
    "    time.sleep(10)\n",
    "except:\n",
    "    lambda_iam_role = iam_client.get_role(RoleName=lambda_function_role)\n",
    "\n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=lambda_function_role,\n",
    "    PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02efd0e9-5174-46e6-9c5b-8303c4f765ee",
   "metadata": {},
   "source": [
    "### Zip the libraries and lambda function to a zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d227780-2845-4c6c-92f5-391aca6bfdc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cab0aed6-64a3-4ded-97de-be9b01e29dc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zip_directory_contents(source_dir, output_filename):\n",
    "    # Ensure the source directory exists\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"Error: The directory {source_dir} does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Create a ZipFile object\n",
    "    with zipfile.ZipFile(output_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Walk through the directory\n",
    "        for root, _, files in os.walk(source_dir):\n",
    "            for file in files:\n",
    "                # Get the full path of the file\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Calculate the arc name (file name within the zip)\n",
    "                arc_name = os.path.relpath(file_path, source_dir)\n",
    "                #print(arc_name)\n",
    "                # Add the file to the zip\n",
    "                zipf.write(file_path, arc_name)\n",
    "\n",
    "    print(f\"Successfully created {output_filename} with the contents of {source_dir}\")\n",
    "\n",
    "# Usage\n",
    "source_directory = './lambda_package'\n",
    "output_zip = 'lambda_archive.zip'\n",
    "\n",
    "zip_directory_contents(source_directory, output_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef6686-d68a-492b-88db-f25dcc342348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a S3 bucket to upload the zip file\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Bucket name\n",
    "bucket_name = 'splunk-bedrock-code-'+account_id\n",
    "\n",
    "# Check if the bucket exists\n",
    "try:\n",
    "    response = s3_client.head_bucket(Bucket=bucket_name)\n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == '404':\n",
    "        # Bucket does not exist, create it\n",
    "        try:\n",
    "            s3_client.create_bucket(Bucket=bucket_name)\n",
    "            print(f\"Bucket '{bucket_name}' created successfully.\")\n",
    "        except ClientError as e:\n",
    "            print(f\"Error creating bucket: {e}\")\n",
    "            raise\n",
    "    else:\n",
    "        # Other error, re-raise the exception\n",
    "        raise\n",
    "\n",
    "# Upload an object to the bucket\n",
    "#object_key = 'lambda_package'\n",
    "zip_file_path = 'lambda_archive'+'.zip'\n",
    "# Upload the file to S3\n",
    "try:\n",
    "    s3_client.upload_file(zip_file_path, bucket_name, zip_file_path)\n",
    "    print(f\"File '{zip_file_path}' uploaded to bucket '{bucket_name}' with key '{zip_file_path}'.\")\n",
    "except ClientError as e:\n",
    "    print(f\"Error uploading file: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "22cca531-ebc6-4359-b83c-0b3329fcfe4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Lambda Function\n",
    "lambda_function = lambda_client.create_function(\n",
    "    FunctionName=lambda_function_name,\n",
    "    Runtime='python3.12',\n",
    "    Timeout=300,\n",
    "    Role=lambda_iam_role['Role']['Arn'],\n",
    "    Code={'S3Bucket': bucket_name,\n",
    "        'S3Key': zip_file_path},\n",
    "    Environment={\n",
    "        'Variables': {\n",
    "            'secret_arn': secret_arn\n",
    "        }\n",
    "        },    \n",
    "    Handler='lambda_function.lambda_handler'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7481b5c5-16e1-473d-81e2-db4da833e4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Optional step to update lambda function with new code, if you make any code changes. Uncomment this block and run.\n",
    "# try:\n",
    "#     response = lambda_client.update_function_code(\n",
    "#         FunctionName=lambda_function_name,\n",
    "#         S3Bucket= bucket_name,\n",
    "#         S3Key= zip_file_path,\n",
    "#         Publish=True  # Create a new version\n",
    "#     )\n",
    "#     print(f\"Successfully updated Lambda function: {lambda_function_name}\")\n",
    "#     print(f\"New version: {response['Version']}\")\n",
    "# except lambda_client.exceptions.ResourceNotFoundException:\n",
    "#     print(f\"Error: Lambda function '{lambda_function_name}' not found.\")\n",
    "# except lambda_client.exceptions.ResourceConflictException:\n",
    "#     print(f\"Error: The function '{lambda_function_name}' is currently updating or in an inconsistent state.\")\n",
    "# except lambda_client.exceptions.InvalidParameterValueException as e:\n",
    "#     print(f\"Error: Invalid parameter value. {str(e)}\")\n",
    "# except lambda_client.exceptions.CodeStorageExceededException:\n",
    "#     print(\"Error: You have exceeded your maximum total code size per account.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An unexpected error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00680d-f695-4851-bde3-03dddd717dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extend Lambda role with IAM policy to retrieve secret manager secret \n",
    "smgr_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"secretsmanager:GetSecretValue\"\n",
    "            ],\n",
    "            \"Resource\": secret_arn\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Add the inline policy to the existing role\n",
    "try:\n",
    "    iam_client.put_role_policy(\n",
    "        RoleName=lambda_function_role,\n",
    "        PolicyName='SecretsManagerAccessInlinePolicy',\n",
    "        PolicyDocument=json.dumps(smgr_policy_document)\n",
    "    )\n",
    "    print(f\"Successfully added inline policy 'SecretsManagerAccessInlinePolicy' to role {lambda_function_role}\")\n",
    "except iam_client.exceptions.LimitExceededException:\n",
    "    print(\"Error: Limit exceeded. The role might have too many inline policies.\")\n",
    "except iam_client.exceptions.NoSuchEntityException:\n",
    "    print(f\"Error: The role '{lambda_function_role}' does not exist.\")\n",
    "except iam_client.exceptions.UnmodifiableEntityException:\n",
    "    print(\"Error: Cannot modify the role. It might be a service-linked role.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding inline policy to role: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d74469-977a-4266-87a3-9eba4e960011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extend Lambda role with IAM policy to invoke Titan Model\n",
    "titan_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"bedrock:InvokeModel\"\n",
    "            ],\n",
    "            \"Resource\": \"arn:aws:bedrock:\"+region+\"::foundation-model/amazon.titan-embed-text-v2:0\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Add the inline policy to the existing role\n",
    "try:\n",
    "    iam_client.put_role_policy(\n",
    "        RoleName=lambda_function_role,\n",
    "        PolicyName='BedRockTitanInlinePolicy',\n",
    "        PolicyDocument=json.dumps(titan_policy_document)\n",
    "    )\n",
    "    print(f\"Successfully added inline policy 'SecretsManagerAccessInlinePolicy' to role {lambda_function_role}\")\n",
    "except iam_client.exceptions.LimitExceededException:\n",
    "    print(\"Error: Limit exceeded. The role might have too many inline policies.\")\n",
    "except iam_client.exceptions.NoSuchEntityException:\n",
    "    print(f\"Error: The role '{lambda_function_role}' does not exist.\")\n",
    "except iam_client.exceptions.UnmodifiableEntityException:\n",
    "    print(\"Error: Cannot modify the role. It might be a service-linked role.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding inline policy to role: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2cd344-7cf3-4526-9751-7e117355a2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "collection_name = 'splunk-vector'\n",
    "# Extend Lambda role with IAM policy for OpenSearch Access\n",
    "aoss_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"aoss:*\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:aoss:\"+region+\":\"+account_id+\":dashboards/default\",\n",
    "                \"arn:aws:aoss:\"+region+\":\"+account_id+\":collection/*\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Add the inline policy to the existing role\n",
    "try:\n",
    "    iam_client.put_role_policy(\n",
    "        RoleName=lambda_function_role,\n",
    "        PolicyName='OpenSearchPolicy',\n",
    "        PolicyDocument=json.dumps(aoss_policy_document)\n",
    "    )\n",
    "    print(f\"Successfully added inline policy 'SecretsManagerAccessInlinePolicy' to role {lambda_function_role}\")\n",
    "except iam_client.exceptions.LimitExceededException:\n",
    "    print(\"Error: Limit exceeded. The role might have too many inline policies.\")\n",
    "except iam_client.exceptions.NoSuchEntityException:\n",
    "    print(f\"Error: The role '{lambda_function_role}' does not exist.\")\n",
    "except iam_client.exceptions.UnmodifiableEntityException:\n",
    "    print(\"Error: Cannot modify the role. It might be a service-linked role.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error adding inline policy to role: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd72e434-0116-4cd8-84d0-f5b98f18a1c5",
   "metadata": {},
   "source": [
    "## Create Agent\n",
    "We will now create the agent. To do so, we first need to create the agent policies that allow bedrock model invocation for a specific foundation model and the agent IAM role with the policy associated to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5baef123-9c42-4d1a-8b97-580f8a88ec3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create IAM policies for agent\n",
    "bedrock_agent_bedrock_allow_policy_statement = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"AmazonBedrockAgentBedrockFoundationModelPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"bedrock:InvokeModel\",\n",
    "            \"Resource\": [\n",
    "                f\"arn:aws:bedrock:{region}::foundation-model/{agent_foundation_model}\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "bedrock_policy_json = json.dumps(bedrock_agent_bedrock_allow_policy_statement)\n",
    "\n",
    "agent_bedrock_policy = iam_client.create_policy(\n",
    "    PolicyName=agent_bedrock_allow_policy_name,\n",
    "    PolicyDocument=bedrock_policy_json\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8805b-3021-4d27-a090-149fca9a57d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create IAM Role for the agent and attach IAM policies\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [{\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"bedrock.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "    }]\n",
    "}\n",
    "\n",
    "assume_role_policy_document_json = json.dumps(assume_role_policy_document)\n",
    "agent_role = iam_client.create_role(\n",
    "    RoleName=agent_role_name,\n",
    "    AssumeRolePolicyDocument=assume_role_policy_document_json\n",
    ")\n",
    "\n",
    "# Pause to make sure role is created\n",
    "time.sleep(10)\n",
    "    \n",
    "iam_client.attach_role_policy(\n",
    "    RoleName=agent_role_name,\n",
    "    PolicyArn=agent_bedrock_policy['Policy']['Arn']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76317e45-c13c-48d2-9498-7bd5fd148897",
   "metadata": {},
   "source": [
    "## Create Agent\n",
    "We will now create the agent. To do so, we first need to create the agent policies that allow bedrock model invocation for a specific foundation model and the agent IAM role with the policy associated to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ef027-f397-45e3-ace3-4860729e1aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_agent_client.create_agent(\n",
    "    agentName=agent_name,\n",
    "    agentResourceRoleArn=agent_role['Role']['Arn'],\n",
    "    description=agent_description,\n",
    "    idleSessionTTLInSeconds=1800,\n",
    "    foundationModel=agent_foundation_model,\n",
    "    instruction=agent_instruction,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9a2c6-c13f-46aa-a826-754e9fa8e93e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_id = response['agent']['agentId']\n",
    "agent_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa837cbb-8cab-4d6d-a08b-2a0905334e04",
   "metadata": {},
   "source": [
    "## Create Agent Action Group\n",
    "We will now create an agent action group that uses the lambda function created earlier. The [`create_agent_action_group`](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-agent/client/create_agent_action_group.html) function provides this functionality. We will use `DRAFT` as the agent version since we haven't yet created an agent version or alias. To inform the agent about the action group capabilities, we provide an action group description.\n",
    "\n",
    "To define the functions using a function schema, you need to provide the `name`, `description` and `parameters` for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2886aec8-566e-448a-ba97-2d9cbcb50149",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_functions = [\n",
    "    {\n",
    "        'name': 'search_aws_sourcetypes',\n",
    "        'description': 'Searches a Vector database and returns right sourcetype for AWS source data',\n",
    "        'parameters': {\n",
    "            \"awssourcetype\": {\n",
    "                \"description\": \"the source type to be searched for a given AWS data\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'get_splunk_fields',\n",
    "        'description': 'Provides list of fields found in a given source type sourcetype. \\\n",
    "        Useful to understand the schema of Splunk source types',\n",
    "        'parameters': {\n",
    "            \"sourcetype\": {\n",
    "                \"description\": \"sourcetype for the schema to be returned\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'get_splunk_results',\n",
    "        'description': 'Executes a Splunk search query and returns the results as JSON data. \\\n",
    "        Give the input search query as string variable.Dont give any search values within quotes unless there is a space in the values. \\\n",
    "        Always provide Splunk sourcetype to get the result. If index is not given use main as the index, otherwise use the index name. \\ \n",
    "        Here is an example SPL Query to query cloudtrail data and get the results grouped by account id, event source and error code: \\ \n",
    "        search index=main sourcetype=aws:cloudtrail | stats count by recipientAccountId, eventSource, eventName, errorCode',\n",
    "        'parameters': {\n",
    "            \"search_query\": {\n",
    "                \"description\": \"splunk search query\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'get_splunk_lookups',\n",
    "        'description': 'Gets Splunk sourcetype as input and returns the list of lookup values for the sourcetype. \\\n",
    "        Useful to identify any lookups associated with sourcetype and is required for the SPL query to execute. \\\n",
    "        This function gets all lookup names for a given sourcetype which the agent can use to get the right lookup values for \\\n",
    "        SPL query by calling the agent get_splunk_lookup_values.',\n",
    "        'parameters': {\n",
    "            \"sourcetype\": {\n",
    "                \"description\": \"source type to get the associated lookups\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'get_splunk_lookup_values',\n",
    "        'description': 'Gets Splunk lookup name as input and returns the lookup values. This function gets all look up values \\\n",
    "        for a given sourcetype which can be useful to rewrite the SPL queries with appropriate lookup values.',\n",
    "        'parameters': {\n",
    "            \"lookup_name\": {\n",
    "                \"description\": \"lookup_name to get all the lookup values\",\n",
    "                \"required\": True,\n",
    "                \"type\": \"string\"\n",
    "            }\n",
    "        }\n",
    "    }    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c57418df-efe8-46bf-96ad-eb3f60eba60b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pause to make sure agent is created\n",
    "time.sleep(30)\n",
    "# Now, we can configure and create an action group here:\n",
    "agent_action_group_response = bedrock_agent_client.create_agent_action_group(\n",
    "    agentId=agent_id,\n",
    "    agentVersion='DRAFT',\n",
    "    actionGroupExecutor={\n",
    "        'lambda': lambda_function['FunctionArn']\n",
    "    },\n",
    "    actionGroupName=agent_action_group_name,\n",
    "    functionSchema={\n",
    "        'functions': agent_functions\n",
    "    },\n",
    "    description=agent_action_group_description\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b48da7-e646-4ac5-b48e-faa287adab3b",
   "metadata": {},
   "source": [
    "## Allowing Agent to invoke Action Group Lambda\n",
    "Before using the action group, we need to allow the agent to invoke the lambda function associated with the action group. This is done via resource-based policy. Let's add the resource-based policy to the lambda function created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7aab1e7f-1405-4b91-9060-6814223d7440",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create allow invoke permission on lambda\n",
    "response = lambda_client.add_permission(\n",
    "    FunctionName=lambda_function_name,\n",
    "    StatementId='allow_bedrock',\n",
    "    Action='lambda:InvokeFunction',\n",
    "    Principal='bedrock.amazonaws.com',\n",
    "    SourceArn=f\"arn:aws:bedrock:{region}:{account_id}:agent/{agent_id}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2211070-317f-49cb-8201-134c32ce2c85",
   "metadata": {},
   "source": [
    "## Preparing Agent\n",
    "\n",
    "Let's create a DRAFT version of the agent that can be used for internal testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1958d4d-c52b-4dc7-a459-0d66f42ac4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = bedrock_agent_client.prepare_agent(\n",
    "    agentId=agent_id\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99e214ee-a9c5-4c59-be32-d8ff8fff3499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pause to make sure agent is prepared\n",
    "time.sleep(30)\n",
    "# USe the Test Alias for the Agent\n",
    "agent_alias_id = \"TSTALIASID\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b061202a-101b-40f8-af2d-70b3b3d62d59",
   "metadata": {},
   "source": [
    "## Invoke Agent\n",
    "\n",
    "Now that we've created the agent, let's use the `bedrock-agent-runtime` client to invoke this agent and perform some tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab95c021-3997-4a96-99e2-2d787d9f0265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting logger\n",
    "logging.basicConfig(format='[%(asctime)s] p%(process)s {%(filename)s:%(lineno)d} %(levelname)s - %(message)s', level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584f2f3-6544-4573-8496-33f1d8f54b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## create a random id for session initiator id\n",
    "session_id:str = str(uuid.uuid1())\n",
    "enable_trace:bool = True\n",
    "end_session:bool = False\n",
    "query_text=\"Can you write and execute SPL to query AWS cloudtrail data.\\\n",
    "I need to see which aws account produces the highest count of non-success error code and by which AWS service and event.\\\n",
    "Give me a table of final results and provide your summary\"\n",
    "# invoke the agent API\n",
    "agentResponse = bedrock_agent_runtime_client.invoke_agent(\n",
    "    inputText=query_text,\n",
    "    agentId=agent_id,\n",
    "    agentAliasId=agent_alias_id, \n",
    "    sessionId=session_id,\n",
    "    enableTrace=enable_trace, \n",
    "    endSession= end_session\n",
    ")\n",
    "\n",
    "\n",
    "logger.info(pprint.pprint(agentResponse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bda8b3a",
   "metadata": {},
   "source": [
    "Review the prompt handling by Bedrock and various agents executions.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b6997-4456-468f-b71e-a9c1be091308",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "event_stream = agentResponse['completion']\n",
    "try:\n",
    "    for event in event_stream:        \n",
    "        if 'chunk' in event:\n",
    "            \n",
    "            data = event['chunk']['bytes']\n",
    "            logger.info(f\"Final answer ->\\n{data.decode('utf8')}\")\n",
    "            agent_answer = data.decode('utf8')\n",
    "            end_event_received = True\n",
    "            # End event indicates that the request finished successfully\n",
    "        elif 'trace' in event:\n",
    "            logger.info(json.dumps(event['trace'], indent=2))\n",
    "        else:\n",
    "            raise Exception(\"unexpected event.\", event)\n",
    "except Exception as e:\n",
    "    raise Exception(\"unexpected event.\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a6238-d8e6-44be-93f2-ac957bb4f989",
   "metadata": {},
   "source": [
    "## Clean up (optional)\n",
    "\n",
    "The next steps are optional and demonstrate how to delete our agent. To delete the agent we need to:\n",
    "\n",
    "1. Delete opensearch index and collection\n",
    "2. Update the action group to disable it\n",
    "3. Delete agent action group\n",
    "4. Delete agent\n",
    "5. Delete lambda function\n",
    "6. Delete the created IAM roles and policies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d055642-0c12-45a6-896d-585f7095594d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete index\n",
    "def delete_index(index_name):\n",
    "    try:\n",
    "        # Check if the index exists\n",
    "        if opensearch_client.indices.exists(index=index_name):\n",
    "            # Delete the index\n",
    "            response = opensearch_client.indices.delete(index=index_name)\n",
    "            if response.get('acknowledged', False):\n",
    "                print(f\"Successfully deleted index: {index_name}\")\n",
    "            else:\n",
    "                print(f\"Failed to delete index: {index_name}\")\n",
    "        else:\n",
    "            print(f\"Index {index_name} does not exist.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while deleting the index: {str(e)}\")\n",
    "\n",
    "# Usage\n",
    "delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef1bc6-e685-4998-8fd8-46837c968de3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = boto3.client('opensearchserverless')\n",
    "\n",
    "def delete_security_policy(policy_name, policy_type):\n",
    "    try:\n",
    "        client.delete_security_policy(\n",
    "            name=policy_name,\n",
    "            type=policy_type\n",
    "        )\n",
    "        print(f\"Deleted {policy_type} security policy: {policy_name}\")\n",
    "    except client.exceptions.ResourceNotFoundException:\n",
    "        print(f\"{policy_type.capitalize()} security policy {policy_name} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting {policy_type} security policy {policy_name}: {str(e)}\")\n",
    "\n",
    "def delete_access_policy(policy_name):\n",
    "    try:\n",
    "        client.delete_access_policy(\n",
    "            name=policy_name,\n",
    "            type='data'\n",
    "        )\n",
    "        print(f\"Deleted access policy: {policy_name}\")\n",
    "    except client.exceptions.ResourceNotFoundException:\n",
    "        print(f\"Access policy {policy_name} not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting access policy {policy_name}: {str(e)}\")\n",
    "\n",
    "def delete_collection(collection_name,collection_id):\n",
    "    try:\n",
    "        response = client.delete_collection(\n",
    "            clientToken=collection_name,\n",
    "            id=collection_id\n",
    "        )\n",
    "        print(f\"Deletion initiated for collection: {collection_name}\")\n",
    "        return response['deleteCollectionDetail']['id']\n",
    "    except client.exceptions.ResourceNotFoundException:\n",
    "        print(f\"Collection {collection_name} not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting collection {collection_name}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def wait_for_collection_deletion(collection_id):\n",
    "    if not collection_id:\n",
    "        return\n",
    "\n",
    "    print(\"Waiting for collection deletion to complete...\")\n",
    "    waiter = client.get_waiter('collection_deleted')\n",
    "    try:\n",
    "        waiter.wait(\n",
    "            ids=[collection_id],\n",
    "            WaiterConfig={\n",
    "                'Delay': 30,\n",
    "                'MaxAttempts': 40\n",
    "            }\n",
    "        )\n",
    "        print(\"Collection deletion completed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error waiting for collection deletion: {str(e)}\")\n",
    "\n",
    "# Usage\n",
    "policy_prefix = f\"{collection_name}\"  # Assuming policies are named with collection name as prefix\n",
    "\n",
    "# Delete security policies\n",
    "delete_security_policy(f\"{policy_prefix}-network-policy\", 'network')\n",
    "delete_security_policy(f\"{policy_prefix}-encryption-policy\", 'encryption')\n",
    "\n",
    "# Delete access policy\n",
    "delete_access_policy(f\"{policy_prefix}-access-policy\")\n",
    "\n",
    "# Delete collection\n",
    "collection_id = endpoint.split('/')[2].split('.')[0]\n",
    "delete_collection_id = delete_collection(collection_name, collection_id)\n",
    "\n",
    "# Wait for collection deletion to complete\n",
    "wait_for_collection_deletion(collection_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b567a6e3-0aba-4288-b628-c7acc39db824",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wait_for_collection_deletion(collection_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b62fe4-2109-4f23-9f23-08a766ae784c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is not needed, you can delete agent successfully after deleting alias only\n",
    "# Additionaly, you need to disable it first\n",
    "action_group_id = agent_action_group_response['agentActionGroup']['actionGroupId']\n",
    "action_group_name = agent_action_group_response['agentActionGroup']['actionGroupName']\n",
    "\n",
    "response = bedrock_agent_client.update_agent_action_group(\n",
    "    agentId=agent_id,\n",
    "    agentVersion='DRAFT',\n",
    "    actionGroupId= action_group_id,\n",
    "    actionGroupName=action_group_name,\n",
    "    actionGroupExecutor={\n",
    "        'lambda': lambda_function['FunctionArn']\n",
    "    },\n",
    "    functionSchema={\n",
    "        'functions': agent_functions\n",
    "    },\n",
    "    actionGroupState='DISABLED',\n",
    ")\n",
    "\n",
    "action_group_deletion = bedrock_agent_client.delete_agent_action_group(\n",
    "    agentId=agent_id,\n",
    "    agentVersion='DRAFT',\n",
    "    actionGroupId= action_group_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1161eed7-3944-4a8e-bdb4-1f20f031f76c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_deletion = bedrock_agent_client.delete_agent(\n",
    "    agentId=agent_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8173b-63c9-49f7-9db7-042e652a4174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete Lambda function\n",
    "lambda_client.delete_function(\n",
    "    FunctionName=lambda_function_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95c82e5-e571-4e26-afef-75a5add892ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete IAM Roles and policies\n",
    "\n",
    "for policy in [agent_bedrock_allow_policy_name]:\n",
    "    iam_client.detach_role_policy(RoleName=agent_role_name, PolicyArn=f'arn:aws:iam::{account_id}:policy/{policy}')\n",
    "    \n",
    "iam_client.detach_role_policy(RoleName=lambda_function_role, PolicyArn='arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole')\n",
    "\n",
    "for role_name in [agent_role_name, lambda_function_role]:\n",
    "    iam_client.delete_role(\n",
    "        RoleName=role_name\n",
    "    )\n",
    "\n",
    "for policy in [agent_bedrock_policy]:\n",
    "    iam_client.delete_policy(\n",
    "        PolicyArn=policy['Policy']['Arn']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4ab8ab-9aa3-4f3f-a3d9-93daaa680089",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We have now experimented with using boto3 SDK and Splunk SDKs to create, invoke and delete a Splunk AI Assistant agent, created using function definitions.\n",
    "\n",
    "## Take aways\n",
    "Adapt this notebook to customize and create new agents using function definitions for your application\n",
    "\n",
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
